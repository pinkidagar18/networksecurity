[ 2026-01-14 20:13:11,294 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2026-01-14 20:13:11,307 ] 107 dagshub - INFO - Accessing as pinkidagar18
[ 2026-01-14 20:13:12,917 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/pinkidagar18/networksecurity "HTTP/1.1 200 OK"
[ 2026-01-14 20:13:14,503 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2026-01-14 20:13:14,507 ] 107 dagshub - INFO - Initialized MLflow to track repo "pinkidagar18/networksecurity"
[ 2026-01-14 20:13:14,508 ] 107 dagshub - INFO - Repository pinkidagar18/networksecurity initialized!
[ 2026-01-14 20:13:22,257 ] 99 root - INFO - Training pipeline initiated via API
[ 2026-01-14 20:13:22,257 ] 38 root - INFO - Start data Ingestion
[ 2026-01-14 20:13:22,257 ] 105 root - INFO - Starting data ingestion process
[ 2026-01-14 20:13:22,258 ] 33 root - INFO - Connecting to MongoDB
[ 2026-01-14 20:13:28,115 ] 49 root - INFO - Successfully fetched data from MongoDB
[ 2026-01-14 20:13:28,210 ] 65 root - INFO - Data exported to feature store successfully
[ 2026-01-14 20:13:28,210 ] 74 root - INFO - Performing train-test split
[ 2026-01-14 20:13:28,312 ] 97 root - INFO - Train-test split completed and files saved
[ 2026-01-14 20:13:28,312 ] 116 root - INFO - Data ingestion completed successfully
[ 2026-01-14 20:13:28,313 ] 41 root - INFO - Data Ingestion completed and artifact: DataIngestionArtifact(trained_file_path='Artifacts\\01_14_2026_20_13_07\\data_ingestion\\ingested\\train.csv', test_file_path='Artifacts\\01_14_2026_20_13_07\\data_ingestion\\ingested\\test.csv')
[ 2026-01-14 20:13:28,320 ] 51 root - INFO - Initiate the data Validation
[ 2026-01-14 20:13:28,401 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:13:28,401 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:13:28,401 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:13:28,402 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:13:28,620 ] 63 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2026-01-14 20:13:28,621 ] 65 root - INFO - Starting data transformation
[ 2026-01-14 20:13:28,654 ] 48 root - INFO - Entered get_data_transformer_object method of Transformation class
[ 2026-01-14 20:13:28,654 ] 53 root - INFO - Initialise KNNImputer with {'missing_values': nan, 'n_neighbors': 3, 'weights': 'uniform'}
[ 2026-01-14 20:13:28,707 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:13:28,713 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:13:28,714 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:13:28,718 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:13:57,538 ] 105 root - INFO - Best model selected: Random Forest
[ 2026-01-14 20:15:31,362 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:15:31,435 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:15:31,436 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:15:31,489 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:15:31,489 ] 151 root - INFO - Model trainer artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_13_07\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.9915556007732221, precision_score=0.9890399837629389, recall_score=0.9940840473276213), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.9699842022116903, precision_score=0.961628817541112, recall_score=0.9784860557768924))
[ 2026-01-14 20:15:31,496 ] 114 root - ERROR - Training pipeline failed: Error occured in python script name [C:\Users\pc\OneDrive\Attachments\Desktop\NETWORKSECURITY\networksecurity\pipeline\training_pipeline.py] line number [112] error message [Error occured in python script name [C:\Users\pc\OneDrive\Attachments\Desktop\NETWORKSECURITY\networksecurity\pipeline\training_pipeline.py] line number [89] error message [name 'TRAINING_BUCKET_NAME' is not defined]]
[ 2026-01-14 20:16:48,441 ] 99 root - INFO - Training pipeline initiated via API
[ 2026-01-14 20:16:48,441 ] 38 root - INFO - Start data Ingestion
[ 2026-01-14 20:16:48,442 ] 105 root - INFO - Starting data ingestion process
[ 2026-01-14 20:16:48,442 ] 33 root - INFO - Connecting to MongoDB
[ 2026-01-14 20:16:53,835 ] 49 root - INFO - Successfully fetched data from MongoDB
[ 2026-01-14 20:16:53,931 ] 65 root - INFO - Data exported to feature store successfully
[ 2026-01-14 20:16:53,931 ] 74 root - INFO - Performing train-test split
[ 2026-01-14 20:16:54,038 ] 97 root - INFO - Train-test split completed and files saved
[ 2026-01-14 20:16:54,038 ] 116 root - INFO - Data ingestion completed successfully
[ 2026-01-14 20:16:54,039 ] 41 root - INFO - Data Ingestion completed and artifact: DataIngestionArtifact(trained_file_path='Artifacts\\01_14_2026_20_13_07\\data_ingestion\\ingested\\train.csv', test_file_path='Artifacts\\01_14_2026_20_13_07\\data_ingestion\\ingested\\test.csv')
[ 2026-01-14 20:16:54,046 ] 51 root - INFO - Initiate the data Validation
[ 2026-01-14 20:16:54,130 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:16:54,131 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:16:54,131 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:16:54,131 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:16:54,341 ] 63 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2026-01-14 20:16:54,342 ] 65 root - INFO - Starting data transformation
[ 2026-01-14 20:16:54,380 ] 48 root - INFO - Entered get_data_transformer_object method of Transformation class
[ 2026-01-14 20:16:54,380 ] 53 root - INFO - Initialise KNNImputer with {'missing_values': nan, 'n_neighbors': 3, 'weights': 'uniform'}
[ 2026-01-14 20:16:54,399 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:16:54,404 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:16:54,404 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:16:54,409 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:17:28,770 ] 105 root - INFO - Best model selected: Random Forest
[ 2026-01-14 20:19:24,219 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:19:24,278 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:19:24,278 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:19:24,344 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:19:24,344 ] 151 root - INFO - Model trainer artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_13_07\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.9915538821613921, precision_score=0.989238578680203, recall_score=0.9938800489596084), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.9711576451995259, precision_score=0.963166144200627, recall_score=0.9792828685258964))
[ 2026-01-14 20:19:24,356 ] 114 root - ERROR - Training pipeline failed: Error occured in python script name [C:\Users\pc\OneDrive\Attachments\Desktop\NETWORKSECURITY\networksecurity\pipeline\training_pipeline.py] line number [112] error message [Error occured in python script name [C:\Users\pc\OneDrive\Attachments\Desktop\NETWORKSECURITY\networksecurity\pipeline\training_pipeline.py] line number [89] error message [name 'TRAINING_BUCKET_NAME' is not defined]]
