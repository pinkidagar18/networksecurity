[ 2026-01-14 20:56:22,285 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2026-01-14 20:56:22,290 ] 107 dagshub - INFO - Accessing as pinkidagar18
[ 2026-01-14 20:57:06,118 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/pinkidagar18/networksecurity "HTTP/1.1 200 OK"
[ 2026-01-14 20:57:49,626 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2026-01-14 20:57:49,628 ] 107 dagshub - INFO - Initialized MLflow to track repo "pinkidagar18/networksecurity"
[ 2026-01-14 20:57:49,629 ] 107 dagshub - INFO - Repository pinkidagar18/networksecurity initialized!
[ 2026-01-14 20:59:03,483 ] 367 root - INFO - Received CSV file with 12 rows and 30 columns
[ 2026-01-14 20:59:03,542 ] 441 root - INFO - Predictions generated: [1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]
[ 2026-01-14 20:59:03,552 ] 449 root - INFO - Predictions saved to prediction_output/output.csv
[ 2026-01-14 20:59:40,887 ] 367 root - INFO - Received CSV file with 12 rows and 30 columns
[ 2026-01-14 20:59:40,926 ] 441 root - INFO - Predictions generated: [1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]
[ 2026-01-14 20:59:40,930 ] 449 root - INFO - Predictions saved to prediction_output/output.csv
[ 2026-01-14 20:59:56,782 ] 367 root - INFO - Received CSV file with 12 rows and 30 columns
[ 2026-01-14 20:59:56,823 ] 441 root - INFO - Predictions generated: [1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]
[ 2026-01-14 20:59:56,827 ] 449 root - INFO - Predictions saved to prediction_output/output.csv
[ 2026-01-14 21:03:09,087 ] 367 root - INFO - Received CSV file with 12 rows and 30 columns
[ 2026-01-14 21:03:09,121 ] 441 root - INFO - Predictions generated: [1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]
[ 2026-01-14 21:03:09,125 ] 449 root - INFO - Predictions saved to prediction_output/output.csv
[ 2026-01-14 21:08:26,711 ] 367 root - INFO - Received CSV file with 12 rows and 30 columns
[ 2026-01-14 21:08:26,749 ] 441 root - INFO - Predictions generated: [1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]
[ 2026-01-14 21:08:26,753 ] 449 root - INFO - Predictions saved to prediction_output/output.csv
[ 2026-01-14 21:09:15,048 ] 99 root - INFO - Training pipeline initiated via API
[ 2026-01-14 21:09:15,049 ] 174 root - INFO - ================================================================================
[ 2026-01-14 21:09:15,049 ] 175 root - INFO - TRAINING PIPELINE STARTED
[ 2026-01-14 21:09:15,049 ] 176 root - INFO - ================================================================================
[ 2026-01-14 21:09:15,049 ] 179 root - INFO - Step 1/4: Data Ingestion
[ 2026-01-14 21:09:15,049 ] 50 root - INFO - Starting data ingestion
[ 2026-01-14 21:09:15,049 ] 105 root - INFO - Starting data ingestion process
[ 2026-01-14 21:09:15,049 ] 33 root - INFO - Connecting to MongoDB
[ 2026-01-14 21:09:31,478 ] 49 root - INFO - Successfully fetched data from MongoDB
[ 2026-01-14 21:09:31,637 ] 65 root - INFO - Data exported to feature store successfully
[ 2026-01-14 21:09:31,637 ] 74 root - INFO - Performing train-test split
[ 2026-01-14 21:09:31,797 ] 97 root - INFO - Train-test split completed and files saved
[ 2026-01-14 21:09:31,798 ] 116 root - INFO - Data ingestion completed successfully
[ 2026-01-14 21:09:31,799 ] 55 root - INFO - Data ingestion completed. Artifact: DataIngestionArtifact(trained_file_path='Artifacts\\01_14_2026_20_55_35\\data_ingestion\\ingested\\train.csv', test_file_path='Artifacts\\01_14_2026_20_55_35\\data_ingestion\\ingested\\test.csv')
[ 2026-01-14 21:09:31,799 ] 183 root - INFO - Step 2/4: Data Validation
[ 2026-01-14 21:09:31,809 ] 70 root - INFO - Starting data validation
[ 2026-01-14 21:09:31,927 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 21:09:31,927 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 21:09:31,927 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 21:09:31,928 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 21:09:32,223 ] 72 root - INFO - Data validation completed. Artifact: DataValidationArtifact(validation_status=None, valid_train_file_path='Artifacts\\01_14_2026_20_55_35\\data_ingestion\\ingested\\train.csv', valid_test_file_path='Artifacts\\01_14_2026_20_55_35\\data_ingestion\\ingested\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='Artifacts\\01_14_2026_20_55_35\\data_validation\\drift_report\\report.yaml')
[ 2026-01-14 21:09:32,228 ] 189 root - INFO - Step 3/4: Data Transformation
[ 2026-01-14 21:09:32,229 ] 86 root - INFO - Starting data transformation
[ 2026-01-14 21:09:32,229 ] 63 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2026-01-14 21:09:32,229 ] 65 root - INFO - Starting data transformation
[ 2026-01-14 21:09:32,293 ] 48 root - INFO - Entered get_data_transformer_object method of Transformation class
[ 2026-01-14 21:09:32,294 ] 53 root - INFO - Initialise KNNImputer with {'missing_values': nan, 'n_neighbors': 3, 'weights': 'uniform'}
[ 2026-01-14 21:09:32,331 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 21:09:32,345 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 21:09:32,346 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 21:09:32,358 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 21:09:32,361 ] 88 root - INFO - Data transformation completed. Artifact: DataTransformationArtifact(transformed_object_file_path='Artifacts\\01_14_2026_20_55_35\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='Artifacts\\01_14_2026_20_55_35\\data_transformation\\transformed\\train.npy', transformed_test_file_path='Artifacts\\01_14_2026_20_55_35\\data_transformation\\transformed\\test.npy')
[ 2026-01-14 21:09:32,361 ] 195 root - INFO - Step 4/4: Model Training
[ 2026-01-14 21:09:32,361 ] 104 root - INFO - Starting model training
[ 2026-01-14 21:09:56,532 ] 105 root - INFO - Best model selected: Random Forest
[ 2026-01-14 21:11:43,716 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 21:11:43,772 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 21:11:43,772 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 21:11:43,819 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 21:11:43,819 ] 151 root - INFO - Model trainer artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_55_35\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.991560752414845, precision_score=0.9884451652138658, recall_score=0.9946960424316605), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.970367443698143, precision_score=0.9623824451410659, recall_score=0.9784860557768924))
[ 2026-01-14 21:11:43,825 ] 106 root - INFO - Model training completed. Artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_55_35\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.991560752414845, precision_score=0.9884451652138658, recall_score=0.9946960424316605), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.970367443698143, precision_score=0.9623824451410659, recall_score=0.9784860557768924))
[ 2026-01-14 21:11:43,826 ] 206 root - INFO - S3 sync disabled. Models saved locally only.
[ 2026-01-14 21:11:43,827 ] 208 root - INFO - ================================================================================
[ 2026-01-14 21:11:43,827 ] 209 root - INFO - TRAINING PIPELINE COMPLETED SUCCESSFULLY
[ 2026-01-14 21:11:43,827 ] 210 root - INFO - ================================================================================
[ 2026-01-14 21:11:43,827 ] 108 root - INFO - Training pipeline completed successfully
