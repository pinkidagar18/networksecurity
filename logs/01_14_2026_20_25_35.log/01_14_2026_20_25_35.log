[ 2026-01-14 20:25:46,152 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2026-01-14 20:25:46,158 ] 107 dagshub - INFO - Accessing as pinkidagar18
[ 2026-01-14 20:25:49,119 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/pinkidagar18/networksecurity "HTTP/1.1 200 OK"
[ 2026-01-14 20:25:51,372 ] 1025 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2026-01-14 20:25:51,376 ] 107 dagshub - INFO - Initialized MLflow to track repo "pinkidagar18/networksecurity"
[ 2026-01-14 20:25:51,378 ] 107 dagshub - INFO - Repository pinkidagar18/networksecurity initialized!
[ 2026-01-14 20:26:08,846 ] 99 root - INFO - Training pipeline initiated via API
[ 2026-01-14 20:26:08,846 ] 174 root - INFO - ================================================================================
[ 2026-01-14 20:26:08,846 ] 175 root - INFO - TRAINING PIPELINE STARTED
[ 2026-01-14 20:26:08,846 ] 176 root - INFO - ================================================================================
[ 2026-01-14 20:26:08,847 ] 179 root - INFO - Step 1/4: Data Ingestion
[ 2026-01-14 20:26:08,847 ] 50 root - INFO - Starting data ingestion
[ 2026-01-14 20:26:08,847 ] 105 root - INFO - Starting data ingestion process
[ 2026-01-14 20:26:08,847 ] 33 root - INFO - Connecting to MongoDB
[ 2026-01-14 20:26:15,886 ] 49 root - INFO - Successfully fetched data from MongoDB
[ 2026-01-14 20:26:16,096 ] 65 root - INFO - Data exported to feature store successfully
[ 2026-01-14 20:26:16,096 ] 74 root - INFO - Performing train-test split
[ 2026-01-14 20:26:16,353 ] 97 root - INFO - Train-test split completed and files saved
[ 2026-01-14 20:26:16,353 ] 116 root - INFO - Data ingestion completed successfully
[ 2026-01-14 20:26:16,354 ] 55 root - INFO - Data ingestion completed. Artifact: DataIngestionArtifact(trained_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\train.csv', test_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\test.csv')
[ 2026-01-14 20:26:16,355 ] 183 root - INFO - Step 2/4: Data Validation
[ 2026-01-14 20:26:16,367 ] 70 root - INFO - Starting data validation
[ 2026-01-14 20:26:16,526 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:26:16,527 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:26:16,527 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:26:16,527 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:26:16,926 ] 72 root - INFO - Data validation completed. Artifact: DataValidationArtifact(validation_status=None, valid_train_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\train.csv', valid_test_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='Artifacts\\01_14_2026_20_25_39\\data_validation\\drift_report\\report.yaml')
[ 2026-01-14 20:26:16,927 ] 189 root - INFO - Step 3/4: Data Transformation
[ 2026-01-14 20:26:16,927 ] 86 root - INFO - Starting data transformation
[ 2026-01-14 20:26:16,927 ] 63 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2026-01-14 20:26:16,927 ] 65 root - INFO - Starting data transformation
[ 2026-01-14 20:26:16,988 ] 48 root - INFO - Entered get_data_transformer_object method of Transformation class
[ 2026-01-14 20:26:16,988 ] 53 root - INFO - Initialise KNNImputer with {'missing_values': nan, 'n_neighbors': 3, 'weights': 'uniform'}
[ 2026-01-14 20:26:17,047 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:26:17,053 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:26:17,053 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:26:17,059 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:26:17,062 ] 88 root - INFO - Data transformation completed. Artifact: DataTransformationArtifact(transformed_object_file_path='Artifacts\\01_14_2026_20_25_39\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='Artifacts\\01_14_2026_20_25_39\\data_transformation\\transformed\\train.npy', transformed_test_file_path='Artifacts\\01_14_2026_20_25_39\\data_transformation\\transformed\\test.npy')
[ 2026-01-14 20:26:17,063 ] 195 root - INFO - Step 4/4: Model Training
[ 2026-01-14 20:26:17,064 ] 104 root - INFO - Starting model training
[ 2026-01-14 20:27:09,192 ] 105 root - INFO - Best model selected: Random Forest
[ 2026-01-14 20:28:07,901 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:28:07,926 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:28:07,927 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:28:07,943 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:28:07,944 ] 151 root - INFO - Model trainer artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_25_39\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.9915538821613921, precision_score=0.989238578680203, recall_score=0.9938800489596084), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.9718811881188119, precision_score=0.9661417322834646, recall_score=0.9776892430278884))
[ 2026-01-14 20:28:07,945 ] 106 root - INFO - Model training completed. Artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_25_39\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.9915538821613921, precision_score=0.989238578680203, recall_score=0.9938800489596084), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.9718811881188119, precision_score=0.9661417322834646, recall_score=0.9776892430278884))
[ 2026-01-14 20:28:07,946 ] 206 root - INFO - S3 sync disabled. Models saved locally only.
[ 2026-01-14 20:28:07,946 ] 208 root - INFO - ================================================================================
[ 2026-01-14 20:28:07,946 ] 209 root - INFO - TRAINING PIPELINE COMPLETED SUCCESSFULLY
[ 2026-01-14 20:28:07,946 ] 210 root - INFO - ================================================================================
[ 2026-01-14 20:28:07,946 ] 108 root - INFO - Training pipeline completed successfully
[ 2026-01-14 20:28:09,382 ] 99 root - INFO - Training pipeline initiated via API
[ 2026-01-14 20:28:09,382 ] 174 root - INFO - ================================================================================
[ 2026-01-14 20:28:09,382 ] 175 root - INFO - TRAINING PIPELINE STARTED
[ 2026-01-14 20:28:09,382 ] 176 root - INFO - ================================================================================
[ 2026-01-14 20:28:09,383 ] 179 root - INFO - Step 1/4: Data Ingestion
[ 2026-01-14 20:28:09,383 ] 50 root - INFO - Starting data ingestion
[ 2026-01-14 20:28:09,383 ] 105 root - INFO - Starting data ingestion process
[ 2026-01-14 20:28:09,383 ] 33 root - INFO - Connecting to MongoDB
[ 2026-01-14 20:28:16,403 ] 49 root - INFO - Successfully fetched data from MongoDB
[ 2026-01-14 20:28:16,624 ] 65 root - INFO - Data exported to feature store successfully
[ 2026-01-14 20:28:16,624 ] 74 root - INFO - Performing train-test split
[ 2026-01-14 20:28:16,830 ] 97 root - INFO - Train-test split completed and files saved
[ 2026-01-14 20:28:16,831 ] 116 root - INFO - Data ingestion completed successfully
[ 2026-01-14 20:28:16,832 ] 55 root - INFO - Data ingestion completed. Artifact: DataIngestionArtifact(trained_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\train.csv', test_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\test.csv')
[ 2026-01-14 20:28:16,832 ] 183 root - INFO - Step 2/4: Data Validation
[ 2026-01-14 20:28:16,846 ] 70 root - INFO - Starting data validation
[ 2026-01-14 20:28:16,997 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:28:16,997 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:28:16,997 ] 32 root - INFO - Required number of columns:2
[ 2026-01-14 20:28:16,998 ] 33 root - INFO - Data frame has columns:31
[ 2026-01-14 20:28:17,606 ] 72 root - INFO - Data validation completed. Artifact: DataValidationArtifact(validation_status=None, valid_train_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\train.csv', valid_test_file_path='Artifacts\\01_14_2026_20_25_39\\data_ingestion\\ingested\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='Artifacts\\01_14_2026_20_25_39\\data_validation\\drift_report\\report.yaml')
[ 2026-01-14 20:28:17,606 ] 189 root - INFO - Step 3/4: Data Transformation
[ 2026-01-14 20:28:17,606 ] 86 root - INFO - Starting data transformation
[ 2026-01-14 20:28:17,607 ] 63 root - INFO - Entered initiate_data_transformation method of DataTransformation class
[ 2026-01-14 20:28:17,607 ] 65 root - INFO - Starting data transformation
[ 2026-01-14 20:28:17,669 ] 48 root - INFO - Entered get_data_transformer_object method of Transformation class
[ 2026-01-14 20:28:17,669 ] 53 root - INFO - Initialise KNNImputer with {'missing_values': nan, 'n_neighbors': 3, 'weights': 'uniform'}
[ 2026-01-14 20:28:17,703 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:28:17,713 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:28:17,713 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:28:17,725 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:28:17,728 ] 88 root - INFO - Data transformation completed. Artifact: DataTransformationArtifact(transformed_object_file_path='Artifacts\\01_14_2026_20_25_39\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='Artifacts\\01_14_2026_20_25_39\\data_transformation\\transformed\\train.npy', transformed_test_file_path='Artifacts\\01_14_2026_20_25_39\\data_transformation\\transformed\\test.npy')
[ 2026-01-14 20:28:17,729 ] 195 root - INFO - Step 4/4: Model Training
[ 2026-01-14 20:28:17,729 ] 104 root - INFO - Starting model training
[ 2026-01-14 20:29:12,357 ] 105 root - INFO - Best model selected: Random Forest
[ 2026-01-14 20:31:03,147 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:31:03,177 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:31:03,178 ] 46 root - INFO - Entered the save_object method of MainUtils class
[ 2026-01-14 20:31:03,218 ] 50 root - INFO - Exited the save_object method of MainUtils class
[ 2026-01-14 20:31:03,218 ] 151 root - INFO - Model trainer artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_25_39\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.9915573186857899, precision_score=0.9888415500101441, recall_score=0.9942880456956344), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.9707740916271722, precision_score=0.9624119028974158, recall_score=0.9792828685258964))
[ 2026-01-14 20:31:03,221 ] 106 root - INFO - Model training completed. Artifact: ModelTrainerArtifact(trained_model_file_path='Artifacts\\01_14_2026_20_25_39\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=0.9915573186857899, precision_score=0.9888415500101441, recall_score=0.9942880456956344), test_metric_artifact=ClassificationMetricArtifact(f1_score=0.9707740916271722, precision_score=0.9624119028974158, recall_score=0.9792828685258964))
[ 2026-01-14 20:31:03,221 ] 206 root - INFO - S3 sync disabled. Models saved locally only.
[ 2026-01-14 20:31:03,221 ] 208 root - INFO - ================================================================================
[ 2026-01-14 20:31:03,221 ] 209 root - INFO - TRAINING PIPELINE COMPLETED SUCCESSFULLY
[ 2026-01-14 20:31:03,222 ] 210 root - INFO - ================================================================================
[ 2026-01-14 20:31:03,222 ] 108 root - INFO - Training pipeline completed successfully
[ 2026-01-14 20:31:44,120 ] 367 root - INFO - Received CSV file with 12 rows and 30 columns
[ 2026-01-14 20:31:44,244 ] 441 root - INFO - Predictions generated: [1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]
[ 2026-01-14 20:31:44,250 ] 449 root - INFO - Predictions saved to prediction_output/output.csv
